{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb139b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Be sure to run the demo/grb_data_exploration.ipynb notebook first to get the preprocessed Fermi data.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import CosineSimilarity\n",
    "from tensorflow.linalg import norm\n",
    "from tensorflow.math import reduce_mean\n",
    "\n",
    "from gw_grb_correlation.Fermi.data_preprocessing import create_dataframe_and_name_column_from_data_files\n",
    "from gw_grb_correlation.Fermi.util import process_data, cosine_similarity_loss\n",
    "\n",
    "from gw_grb_correlation.Fermi.visualization import evaluate_model_and_plot_accurracy\n",
    "from gw_grb_correlation.Fermi.util import convert_cartesian_to_spherical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ac804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "\"\"\"\n",
    "fermi_data = create_dataframe_and_name_column_from_data_files(data_type='fermi')\n",
    "\n",
    "\"\"\"\n",
    "List of detectors\n",
    "\"\"\"\n",
    "detectors = [f\"n{i}\" for i in range(10)] + [\"na\", \"nb\", \"b0\", \"b1\"]\n",
    "\n",
    "\"\"\"\n",
    " Define input columns\n",
    "\"\"\"\n",
    "PH_CNT_columns = [f\"{detector}_PH_CNT\" for detector in detectors]\n",
    "TRIG_columns = [f\"{detector}_TRIG\" for detector in detectors]\n",
    "Orientation_columns = ['QSJ_1', 'QSJ_2', 'QSJ_3', 'QSJ_4']\n",
    "fermi_data[PH_CNT_columns] = np.array(fermi_data[PH_CNT_columns].values.astype(np.float64)) * np.array(fermi_data[TRIG_columns].values.astype(np.float64))\n",
    "\n",
    "all_data_columns = Orientation_columns + TRIG_columns + PH_CNT_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b2bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define function to train the GRB localization model\n",
    "\"\"\"\n",
    "# Custom cosine similarity loss\n",
    "def cosine_similarity_loss(y_true, y_pred):\n",
    "    import tensorflow as tf\n",
    "    dot_product = reduce_sum(y_true * y_pred, axis=-1)\n",
    "    norm_true = norm(y_true, axis=-1)\n",
    "    norm_pred = norm(y_pred, axis=-1)\n",
    "    cosine_sim = dot_product / (norm_true * norm_pred)\n",
    "    return -cosine_sim\n",
    "\n",
    "def train_GRB_localization_model(fermi_data, input_columns):\n",
    "    \"\"\"\n",
    "    Train a GRB localization model using the provided Fermi data.\n",
    "\n",
    "    Parameters:\n",
    "    fermi_data (DataFrame): The Fermi data containing the necessary columns.\n",
    "    input_columns (list): List of input columns to be used for training.\n",
    "\n",
    "    Returns:\n",
    "    model: The trained Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets\n",
    "    \"\"\"\n",
    "    X_scaled, X_train_scaled, X_test_scaled, y, y_train, y_test = process_data(fermi_data, input_columns)\n",
    "\n",
    "    \"\"\"\n",
    "    Define model with Dropout\n",
    "    \"\"\"\n",
    "    Dropout_rate = 0.05\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        Dropout(Dropout_rate),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(Dropout_rate),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(Dropout_rate),\n",
    "        Dense(3, activation=None),\n",
    "    ])\n",
    "\n",
    "    \"\"\"\n",
    "    Compile model\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00002),\n",
    "        loss=cosine_similarity_loss,\n",
    "        metrics=[CosineSimilarity(name='cosine_similarity')]\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    Print model summary\n",
    "    \"\"\"\n",
    "    model.summary()\n",
    "\n",
    "    \"\"\"\n",
    "    Train model\n",
    "    \"\"\"\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=400,\n",
    "        batch_size=16,\n",
    "        validation_data=(X_test_scaled, y_test)\n",
    "    )\n",
    "\n",
    "    model_path = \"model.h5\"\n",
    "    \"\"\"\n",
    "    Save the trained model\n",
    "    \"\"\"\n",
    "    model.save(model_path)\n",
    "    print(f\"Model trained and saved as {model_path}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate model and plot accuracy\n",
    "    \"\"\"\n",
    "    train_acc, val_acc = evaluate_model_and_plot_accurracy(model, history, X_test_scaled, y_test)\n",
    "    return model, X_scaled, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c537067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Train the model with all data\n",
    "\"\"\"\n",
    "model, X_scaled, val_acc_all_data = train_GRB_localization_model(fermi_data, all_data_columns)\n",
    "\n",
    "\"\"\"\n",
    " Make predictions based on the trained model\n",
    "\"\"\"\n",
    "predictions = model.predict(X_scaled)\n",
    "\n",
    "\"\"\"\n",
    " Convert predictions from Cartesian to spherical coordinates (RA, DEC)\n",
    "\"\"\"\n",
    "RA_DEC_predictions = np.array([convert_cartesian_to_spherical(pred) for pred in predictions])\n",
    "fermi_predict_data = fermi_data.copy()\n",
    "\n",
    "fermi_predict_data['RA'] = RA_DEC_predictions[:, 0]\n",
    "fermi_predict_data['DEC'] = RA_DEC_predictions[:, 1]\n",
    "\n",
    "\"\"\"\n",
    " Save the predictions to a CSV file\n",
    "\"\"\"\n",
    "fermi_predict_data.to_csv(\"fermi_predict_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b0deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will now do time correlation analysis again with the new localization data predicted by the model.\n",
    "We will filter out short GRB data and find matched GRB-GW event pairs using the new location data of short GRBs.\n",
    "\"\"\"\n",
    "from gw_grb_correlation.Fermi.util import filtering\n",
    "from gw_grb_correlation.Fermi.util import read_GW_data, remove_duplicate_times_in_gw_data, compare_time_within_range\n",
    "\n",
    "\"\"\"\n",
    "Filter out short GRB data\n",
    "\"\"\"\n",
    "short_GRB_data = filtering(fermi_predict_data, criteria={'T90': lambda x: x <= 2.1})\n",
    "\n",
    "\"\"\"\n",
    "Load GW data\n",
    "\"\"\"\n",
    "gw_data = read_GW_data(f\"./gw_data/totalgwdata.csv\")\n",
    "gw_times = remove_duplicate_times_in_gw_data(gw_data)\n",
    "\n",
    "\"\"\"\n",
    "Find matched GRB-GW event pairs using new location data of short GRBs from the model\n",
    "\"\"\"\n",
    "match = compare_time_within_range(short_GRB_data, gw_times, time_range_seconds=86400*3)\n",
    "filtered_gw_events = gw_data[gw_data['times'].isin(match['gw_time'])]\n",
    "\n",
    "\"\"\"\n",
    "Save the matched GRB-GW event pairs and filtered GW events to CSV files\n",
    "\"\"\"\n",
    "match.to_csv(\"GRB_GW_event_pairs_predict.csv\", index=False)\n",
    "filtered_gw_events.to_csv(\"Filtered_GW_events_predict.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time, we test model trained without spacecraft orientation data\n",
    "\"\"\"\n",
    "no_spacecraft_columns = TRIG_columns + PH_CNT_columns\n",
    "model, X_scaled, val_acc_no_ori = train_GRB_localization_model(fermi_data, no_spacecraft_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time, we test model trained without trigger data\n",
    "\"\"\"\n",
    "no_trigger_columns = PH_CNT_columns + Orientation_columns\n",
    "model, X_scaled, val_acc_no_trig = train_GRB_localization_model(fermi_data, no_trigger_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ab082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This time, we test model trained without photon count data\n",
    "\"\"\"\n",
    "no_pht_cnt_columns = TRIG_columns + Orientation_columns\n",
    "model, X_scaled, val_acc_no_pht_cnt = train_GRB_localization_model(fermi_data, no_pht_cnt_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare the validation accuracies of the models trained with different data combinations\n",
    "\"\"\"\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val_acc_all_data, label='Trained with all data')\n",
    "plt.plot(val_acc_no_ori, label='Trained without spacecraft orientation')\n",
    "plt.plot(val_acc_no_trig, label='Trained without trigger data')\n",
    "plt.plot(val_acc_no_pht_cnt, label='Trained without photon count data')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Validation Cosine Similarity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
